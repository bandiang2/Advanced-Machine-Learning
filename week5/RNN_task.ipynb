{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u5boYtiwkBs",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71NvHHZoxbn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-8yPVW4xXmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3e7c9942-42ae-4caf-8fbd-661a1ad8bc9b"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-12-29 13:10:08--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-29 13:10:08 (61.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "s6BB7FTSwkBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73e552c9-10b4-4193-d834-11e455c71417"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX6BnNTVwkB1",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "cFyCo1ZxwkB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "QHHDZjJpwkB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "115cba99-bc9a-4132-9631-38ba9173d8c3"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "MrqpL3NZwkB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "957df4db-23f4-4e2f-e934-aef36dd293cf"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlWfpQF2wkCA",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "7bZsx5e2wkCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9d326782-1fab-4e05-9422-868b56013972"
      },
      "source": [
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(pad_token)\n",
        "print(tokens)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'L', 'u', 'a', 'e', 'S', 'U', 'y', 'l', 'c', 'E', 'C', 't', 'A', 'P', 'i', 'p', 'N', 'K', 'J', 'T', 'F', 'v', 'm', 'r', 'w', \"'\", 'O', '#', 'n', 'k', 'M', ' ', 's', 'd', 'Q', 'z', 'j', 'h', 'o', 'I', 'W', 'Y', 'B', 'H', 'g', 'X', 'G', 'Z', 'x', 'f', 'D', 'R', 'q', 'b', 'V', '-'}\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlVeJ3jywkCE",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "B1j-0EDHwkCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "efbd01ad-2f6d-4cce-d836-94922ab9053f"
      },
      "source": [
        "token_to_id = {s : i for i, s in enumerate(tokens)} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "print(token_to_id)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'L': 0, 'u': 1, 'a': 2, 'e': 3, 'S': 4, 'U': 5, 'y': 6, 'l': 7, 'c': 8, 'E': 9, 'C': 10, 't': 11, 'A': 12, 'P': 13, 'i': 14, 'p': 15, 'N': 16, 'K': 17, 'J': 18, 'T': 19, 'F': 20, 'v': 21, 'm': 22, 'r': 23, 'w': 24, \"'\": 25, 'O': 26, '#': 27, 'n': 28, 'k': 29, 'M': 30, ' ': 31, 's': 32, 'd': 33, 'Q': 34, 'z': 35, 'j': 36, 'h': 37, 'o': 38, 'I': 39, 'W': 40, 'Y': 41, 'B': 42, 'H': 43, 'g': 44, 'X': 45, 'G': 46, 'Z': 47, 'x': 48, 'f': 49, 'D': 50, 'R': 51, 'q': 52, 'b': 53, 'V': 54, '-': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "owN6RjeewkCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "RjuhIeNGwkCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "839f59d5-5b59-475c-dc26-06f3280df9d4"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[31 12 53  2 44  2  3  7 27]\n",
            " [31 46  7 38 23  6 27 27 27]\n",
            " [31 13 23 14 32 32 14  3 27]\n",
            " [31 46 14 38 21  2 28 28  3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYt0RilqwkCO",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"./rnn.png\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "IMOG4X4wwkCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ff5576cf-69b2-4292-bac8-c4ed664a37c2"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "Z6THNPbUwkCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln6xmUj1wkCW",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"./char-nn.png\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "H0Qo_SZOwkCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv5V0YtowkCa",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "8Or6DfDdwkCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f423979c-616b-41dc-88cd-791e6abd7f08"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcwxXbOPwkCd",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "jffVIa9mwkCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BPwPqKdwkCh",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "4Uu3RXFbwkCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6XtfpxkwkCk",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "jEOy-WaTwkCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f7be22fa-d4b7-46f6-e5df-7149ce601342"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evo9qrM6wkCo",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "eAWGWzaJwkCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "UNInTkBvwkCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "29_9PjQ_wkCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d3daaad2-fcb0-47aa-c79a-64f5d4008f2d"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Jhiensa\n",
            " Oree\n",
            " Ravile\n",
            " Ghmahedte\n",
            " Tencone\n",
            " Memil\n",
            " Kirhi\n",
            " Reds\n",
            " Ruallte\n",
            " Moner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "0JA15GEOwkC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0d3932c7-4119-423e-b866-d2dd4cbe74c4"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpee\n",
            " Trumpa\n",
            " Trumpo\n",
            " Trumphe\n",
            " Trumpie\n",
            " Trumpie\n",
            " Trumpe\n",
            " Trumpeel\n",
            " Trumpien\n",
            " Trumpa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NyWdp18wkC2",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "3zu9zX1JwkC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"GsNOyfmn98LTSTv7\"\n",
        "COURSERA_EMAIL = \"amassoua@aimsammi.org\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Ix7DRwDrwkC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8369c34-1e61-4400-9534-b860f8d0c123"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTXINZ_ewkC8",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "qDTRd2FlwkC9",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "PRCcWSgmwkC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "61ee6657-f768-44b9-88f3-f6905bfc3cd4"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-24-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_26rRZDGwkDA",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "UOVtS_XJwkDA",
        "colab_type": "code",
        "colab": {},
        "outputId": "6779cadf-302e-445e-b38e-c6502c1a74ae"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "5epGD6kcwkDD",
        "colab_type": "code",
        "colab": {},
        "outputId": "f0f3c7f1-cacd-4d62-e6f7-d47e047bf390"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkTZuw6twkDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}